{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCdDO0AHQbEJAyUSDb/EA6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asrafulasf72/Data-Mining-Algorithm/blob/main/Apriori_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqYBKSklFhj9"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations, chain\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_frequent_1_itemsets(transactions, min_support_count):\n",
        "    counts = defaultdict(int)\n",
        "    for t in transactions:\n",
        "        for item in t:\n",
        "            counts[frozenset([item])] += 1\n",
        "    return {itemset: cnt for itemset, cnt in counts.items() if cnt >= min_support_count}"
      ],
      "metadata": {
        "id": "YvFj2UvGFrlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_infrequent_subset(candidate, prev_freq_itemsets):\n",
        "    k = len(candidate)\n",
        "    for subset in combinations(candidate, k - 1):\n",
        "        if frozenset(subset) not in prev_freq_itemsets:\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "JaRPMUFZFumv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_candidates(prev_freq_itemsets, k):\n",
        "    prev_items = list(prev_freq_itemsets.keys())\n",
        "    candidates = set()\n",
        "    n = len(prev_items)\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            union = prev_items[i] | prev_items[j]\n",
        "            if len(union) == k and not has_infrequent_subset(union, prev_freq_itemsets):\n",
        "                candidates.add(union)\n",
        "    return candidates"
      ],
      "metadata": {
        "id": "QPIBUUJSFwKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_supports(transactions, candidates):\n",
        "    counts = defaultdict(int)\n",
        "    for t in transactions:\n",
        "        tset = set(t)\n",
        "        for c in candidates:\n",
        "            if c.issubset(tset):\n",
        "                counts[c] += 1\n",
        "    return counts"
      ],
      "metadata": {
        "id": "MktXjFAdF0W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apriori(transactions, min_support=0.5, min_confidence=0.7):\n",
        "    \"\"\"\n",
        "    transactions: list of transactions (each transaction is a list or set)\n",
        "    min_support: relative threshold (0–1)\n",
        "    min_confidence: relative threshold (0–1)\n",
        "    returns: frequent itemsets and association rules\n",
        "    \"\"\"\n",
        "    n_transactions = len(transactions)\n",
        "    min_support_count = max(1, int(min_support * n_transactions))\n",
        "\n",
        "    # Step 1: Frequent 1-itemsets\n",
        "    L1 = get_frequent_1_itemsets(transactions, min_support_count)\n",
        "    frequent_itemsets = dict(L1)\n",
        "\n",
        "    k = 2\n",
        "    prev_L = L1\n",
        "    while prev_L:\n",
        "        candidates = generate_candidates(prev_L, k)\n",
        "        if not candidates:\n",
        "            break\n",
        "\n",
        "        candidate_counts = count_supports(transactions, candidates)\n",
        "        Lk = {c: cnt for c, cnt in candidate_counts.items() if cnt >= min_support_count}\n",
        "\n",
        "        frequent_itemsets.update(Lk)\n",
        "        prev_L = Lk\n",
        "        k += 1\n",
        "\n",
        "    support_counts = frequent_itemsets\n",
        "    rules = []\n",
        "    for itemset, itemset_count in support_counts.items():\n",
        "        if len(itemset) < 2:\n",
        "            continue\n",
        "\n",
        "        subsets = chain.from_iterable(combinations(itemset, r) for r in range(1, len(itemset)))\n",
        "        for ante in subsets:\n",
        "            ante = frozenset(ante)\n",
        "            cons = itemset - ante\n",
        "            if not cons:\n",
        "                continue\n",
        "\n",
        "            support = itemset_count / n_transactions\n",
        "            ante_count = support_counts.get(ante)\n",
        "            if ante_count is None or ante_count == 0:\n",
        "                continue\n",
        "\n",
        "            confidence = itemset_count / ante_count\n",
        "            if confidence >= min_confidence:\n",
        "                rules.append((ante, cons, round(support, 4), round(confidence, 4)))\n",
        "\n",
        "    rules.sort(key=lambda x: (x[3], x[2]), reverse=True)\n",
        "    return frequent_itemsets, rules"
      ],
      "metadata": {
        "id": "N8V92HNwGA9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    transactions = [\n",
        "        ['milk', 'bread', 'butter'],\n",
        "        ['beer', 'bread'],\n",
        "        ['milk', 'bread', 'butter', 'beer'],\n",
        "        ['bread', 'butter'],\n",
        "        ['milk', 'bread'],\n",
        "        ['beer', 'butter']\n",
        "    ]\n",
        "\n",
        "    # You can adjust these values to test\n",
        "    min_support = 0.5\n",
        "    min_confidence = 0.7\n",
        "\n",
        "    freq_itemsets, rules = apriori(transactions, min_support, min_confidence)\n",
        "\n",
        "    print(\"=== Frequent Itemsets ===\")\n",
        "    for itemset, count in sorted(freq_itemsets.items(), key=lambda x: (-len(x[0]), -x[1])):\n",
        "        print(f\"{set(itemset)} -> support count: {count}\")\n",
        "\n",
        "    print(\"\\n=== Association Rules ===\")\n",
        "    for ante, cons, support, confidence in rules:\n",
        "        print(f\"{set(ante)} -> {set(cons)} | support={support:.2f}, confidence={confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFgsUMNVGoZf",
        "outputId": "f2982982-cc62-4405-a95c-91cfc9cfdf43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Frequent Itemsets ===\n",
            "{'milk', 'bread'} -> support count: 3\n",
            "{'bread', 'butter'} -> support count: 3\n",
            "{'bread'} -> support count: 5\n",
            "{'butter'} -> support count: 4\n",
            "{'milk'} -> support count: 3\n",
            "{'beer'} -> support count: 3\n",
            "\n",
            "=== Association Rules ===\n",
            "{'milk'} -> {'bread'} | support=0.50, confidence=1.00\n",
            "{'butter'} -> {'bread'} | support=0.50, confidence=0.75\n"
          ]
        }
      ]
    }
  ]
}