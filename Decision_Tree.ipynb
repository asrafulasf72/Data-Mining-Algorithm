{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBK6nWeme3j7+zDyW9zno9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asrafulasf72/Data-Mining-Algorithm/blob/main/Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i28q-7iTI3Kg"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gini_impurity(labels):\n",
        "    \"\"\"Calculate Gini impurity for a list of class labels.\"\"\"\n",
        "    _, counts = np.unique(labels, return_counts=True)\n",
        "    probabilities = counts / counts.sum()\n",
        "    return 1 - np.sum(probabilities ** 2)"
      ],
      "metadata": {
        "id": "MnjmZ9AVJ7-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(left_labels, right_labels, current_impurity):\n",
        "    \"\"\"Calculate information gain after splitting.\"\"\"\n",
        "    total = len(left_labels) + len(right_labels)\n",
        "    p_left = len(left_labels) / total\n",
        "    p_right = len(right_labels) / total\n",
        "\n",
        "    return current_impurity - (p_left * gini_impurity(left_labels) +\n",
        "                               p_right * gini_impurity(right_labels))"
      ],
      "metadata": {
        "id": "CxRW913-KS5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(X, y, feature_index, threshold):\n",
        "    \"\"\"Split dataset based on a feature threshold.\"\"\"\n",
        "    left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
        "    right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
        "    return X[left_indices], y[left_indices], X[right_indices], y[right_indices]"
      ],
      "metadata": {
        "id": "YqEEPmVeKucB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TreeNode:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value"
      ],
      "metadata": {
        "id": "wbGMGagfLXNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        num_classes = len(np.unique(y))\n",
        "\n",
        "        # Stop conditions (leaf node)\n",
        "        if (depth == self.max_depth or\n",
        "            num_classes == 1 or\n",
        "            num_samples < self.min_samples_split):\n",
        "            leaf_value = self._majority_class(y)\n",
        "            return TreeNode(value=leaf_value)\n",
        "\n",
        "        best_feature, best_threshold, best_gain = None, None, -1\n",
        "        current_impurity = gini_impurity(y)\n",
        "\n",
        "        # Search best split\n",
        "        for feature in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature])\n",
        "            for threshold in thresholds:\n",
        "                X_left, y_left, X_right, y_right = split_dataset(X, y, feature, threshold)\n",
        "                if len(y_left) == 0 or len(y_right) == 0:\n",
        "                    continue\n",
        "\n",
        "                gain = information_gain(y_left, y_right, current_impurity)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        # No useful split found\n",
        "        if best_gain == -1:\n",
        "            leaf_value = self._majority_class(y)\n",
        "            return TreeNode(value=leaf_value)\n",
        "\n",
        "        # Make recursive splits\n",
        "        X_left, y_left, X_right, y_right = split_dataset(X, y, best_feature, best_threshold)\n",
        "        left_child = self._build_tree(X_left, y_left, depth + 1)\n",
        "        right_child = self._build_tree(X_right, y_right, depth + 1)\n",
        "\n",
        "        return TreeNode(best_feature, best_threshold, left_child, right_child)\n",
        "\n",
        "    def _majority_class(self, y):\n",
        "        values, counts = np.unique(y, return_counts=True)\n",
        "        return values[np.argmax(counts)]\n",
        "\n",
        "    # Prediction for one sample\n",
        "    def _predict_one(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._predict_one(x, node.left)\n",
        "        else:\n",
        "            return self._predict_one(x, node.right)\n",
        "\n",
        "    # Prediction for all samples\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_one(sample, self.root) for sample in X])\n",
        "\n",
        "\n",
        "# ----------------------------------------------\n",
        "# Example usage\n",
        "# ----------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Simple dataset\n",
        "    X = np.array([\n",
        "        [2.7, 2.5],\n",
        "        [1.3, 3.3],\n",
        "        [3.1, 1.8],\n",
        "        [1.0, 1.0],\n",
        "        [3.0, 3.0]\n",
        "    ])\n",
        "    y = np.array([0, 0, 1, 1, 0])\n",
        "\n",
        "    clf = DecisionTreeClassifier(max_depth=3)\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    predictions = clf.predict(X)\n",
        "    print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "id": "stb3Vos3Le2w",
        "outputId": "a4e92f12-f4df-4a2c-aa78-b7cde5dedd14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 0 1 1 0]\n"
          ]
        }
      ]
    }
  ]
}